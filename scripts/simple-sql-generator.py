#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é˜¿é‡Œäº‘Flink SQLä½œä¸šç”Ÿæˆå™¨ï¼ˆç®€åŒ–ç‰ˆï¼Œä¸ä¾èµ–jinja2ï¼‰
æ ¹æ®é…ç½®æ–‡ä»¶ç”Ÿæˆå¯ç›´æ¥åœ¨é˜¿é‡Œäº‘Flink SQLå¹³å°è¿è¡Œçš„SQLæ–‡ä»¶

@author: yangfanlin
@date: 2025-01-17
"""

import json
import os
import sys
from datetime import datetime

def generate_aliyun_flink_sql(config):
    """ç”Ÿæˆé˜¿é‡Œäº‘Flink SQLä½œä¸š"""
    
    domain = config["domain"]
    job_name = config["job_name"]
    source_table = config["source_table"]
    dim_tables = config.get("dim_tables", [])
    result_table = config["result_table"]
    event_types = config.get("event_types", [])
    parallelism = config.get("parallelism", 2)
    
    # ç”ŸæˆSQLå†…å®¹
    sql_content = f"""-- {job_name}
-- é˜¿é‡Œäº‘Flink SQLä½œä¸šè„šæœ¬
-- ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
-- ä¸šåŠ¡åŸŸ: {domain}
-- 
-- ä½¿ç”¨è¯´æ˜ï¼š
-- 1. å°†æ­¤SQLå†…å®¹å¤åˆ¶åˆ°é˜¿é‡Œäº‘Flink SQLå¼€å‘å¹³å°
-- 2. æ ¹æ®å®é™…ç¯å¢ƒä¿®æ”¹é…ç½®å‚æ•°ï¼ˆç”¨${{}}åŒ…å›´çš„å˜é‡ï¼‰
-- 3. åˆ›å»ºä½œä¸šå¹¶æäº¤è¿è¡Œ

-- =============================================
-- 1. åˆ›å»ºKafkaæºè¡¨
-- =============================================
CREATE TABLE {source_table['name']} (
"""
    
    # æ·»åŠ æºè¡¨å­—æ®µ
    for i, field in enumerate(source_table['fields']):
        comment = f" COMMENT '{field['comment']}'" if field.get('comment') else ""
        comma = "," if i < len(source_table['fields']) - 1 else ""
        sql_content += f"    {field['name']:<20} {field['type']:<15}{comment}{comma}\n"
    
    sql_content += """    -- è®¡ç®—åˆ—ï¼šå¤„ç†æ—¶é—´
    proc_time AS PROCTIME(),
    -- è®¡ç®—åˆ—ï¼šäº‹ä»¶æ—¶é—´
    event_time AS TO_TIMESTAMP_LTZ(`timestamp`, 3),
    -- æ°´å°å®šä¹‰ï¼šå…è®¸5ç§’ä¹±åº
    WATERMARK FOR event_time AS event_time - INTERVAL '5' SECOND
) WITH (
    'connector' = 'kafka',
    'topic' = '${ kafka.input.topic }',
    'properties.bootstrap.servers' = '${ kafka.bootstrap.servers }',
    'properties.group.id' = '${ kafka.group.id }',
    'scan.startup.mode' = 'latest-offset',
    'format' = 'json',
    'json.fail-on-missing-field' = 'false',
    'json.ignore-parse-errors' = 'true'
);

"""
    
    # æ·»åŠ ç»´è¡¨
    if dim_tables:
        sql_content += """-- =============================================
-- 2. åˆ›å»ºMySQLç»´è¡¨
-- =============================================
"""
        for dim_table in dim_tables:
            sql_content += f"-- {dim_table['name']} ç»´è¡¨\n"
            sql_content += f"CREATE TABLE {dim_table['name']} (\n"
            
            for i, field in enumerate(dim_table['fields']):
                comment = f" COMMENT '{field['comment']}'" if field.get('comment') else ""
                comma = "," if i < len(dim_table['fields']) - 1 else ""
                sql_content += f"    {field['name']:<20} {field['type']:<15}{comment}{comma}\n"
            
            sql_content += f"""    PRIMARY KEY ({dim_table['key_field']}) NOT ENFORCED
) WITH (
    'connector' = 'jdbc',
    'url' = '${{ mysql.url }}',
    'username' = '${{ mysql.username }}',
    'password' = '${{ mysql.password }}',
    'table-name' = '{dim_table['name']}',
    -- ç»´è¡¨æŸ¥è¯¢ç¼“å­˜é…ç½®
    'lookup.cache.max-rows' = '1000',
    'lookup.cache.ttl' = '60s',
    'lookup.max-retries' = '3',
    'lookup.cache.caching-missing-key' = 'true'
);

"""
    
    # æ·»åŠ ç»“æœè¡¨
    sql_content += """-- =============================================
-- 3. åˆ›å»ºMySQLç»“æœè¡¨
-- =============================================
"""
    sql_content += f"CREATE TABLE {result_table['name']} (\n"
    
    for i, field in enumerate(result_table['fields']):
        comment = f" COMMENT '{field['comment']}'" if field.get('comment') else ""
        comma = "," if i < len(result_table['fields']) - 1 else ""
        sql_content += f"    {field['name']:<20} {field['type']:<15}{comment}{comma}\n"
    
    sql_content += f"""    PRIMARY KEY ({result_table['key_field']}) NOT ENFORCED
) WITH (
    'connector' = 'jdbc',
    'url' = '${{ mysql.url }}',
    'username' = '${{ mysql.username }}',
    'password' = '${{ mysql.password }}',
    'table-name' = '{result_table['name']}',
    -- æ‰¹é‡å†™å…¥é…ç½®
    'sink.buffer-flush.max-rows' = '100',
    'sink.buffer-flush.interval' = '1s',
    'sink.max-retries' = '3',
    'sink.parallelism' = '{parallelism}'
);

-- =============================================
-- 4. ä¸»è¦ä¸šåŠ¡å¤„ç†SQL
-- =============================================
INSERT INTO {result_table['name']}
SELECT 
    -- åŸºç¡€å­—æ®µ
    s.eventId as event_id,
    s.domain,
    s.type,
"""
    
    # æ·»åŠ SELECTå­—æ®µ
    for i, field in enumerate(result_table['select_fields']):
        comma = "," if i < len(result_table['select_fields']) - 1 else ""
        sql_content += f"    {field}{comma}\n"
    
    sql_content += f"FROM {source_table['name']} s \n"
    
    # æ·»åŠ ç»´è¡¨å…³è”
    if dim_tables:
        sql_content += "-- ç»´è¡¨å…³è”\n"
        for dim_table in dim_tables:
            sql_content += f"LEFT JOIN {dim_table['name']} FOR SYSTEM_TIME AS OF s.proc_time AS {dim_table['alias']}\n"
            sql_content += f"    ON JSON_VALUE(s.payload, '$.{dim_table['join_field']}') = {dim_table['alias']}.{dim_table['key_field']}\n"
    
    sql_content += "WHERE \n"
    sql_content += "    -- è¿‡æ»¤æ¡ä»¶ï¼šåªå¤„ç†æŒ‡å®šçš„äº‹ä»¶ç±»å‹\n"
    
    # æ·»åŠ äº‹ä»¶ç±»å‹è¿‡æ»¤
    event_type_list = "', '".join(event_types)
    sql_content += f"    s.type IN ('{event_type_list}')\n"
    sql_content += f"    -- è¿‡æ»¤æ¡ä»¶ï¼šåªå¤„ç†æŒ‡å®šçš„ä¸šåŠ¡åŸŸ\n"
    sql_content += f"    AND s.domain = '{domain}'\n"
    sql_content += f"    -- è¿‡æ»¤æ¡ä»¶ï¼šè¿‡æ»¤ç©ºäº‹ä»¶ID\n"
    sql_content += f"    AND s.eventId IS NOT NULL;\n\n"
    
    # æ·»åŠ é…ç½®è¯´æ˜
    sql_content += f"""-- =============================================
-- é…ç½®å‚æ•°è¯´æ˜
-- =============================================
/*
éƒ¨ç½²æ—¶éœ€è¦é…ç½®çš„å‚æ•°ï¼š
- kafka.input.topic: Kafkaè¾“å…¥Topicåç§°
- kafka.bootstrap.servers: Kafkaé›†ç¾¤åœ°å€
- kafka.group.id: æ¶ˆè´¹è€…ç»„ID
- mysql.url: MySQLæ•°æ®åº“è¿æ¥åœ°å€
- mysql.username: MySQLç”¨æˆ·å
- mysql.password: MySQLå¯†ç 

ç¤ºä¾‹é…ç½®:
kafka.input.topic={domain}-events
kafka.bootstrap.servers=your-kafka-cluster:9092
kafka.group.id={domain}-event-processor
mysql.url=jdbc:mysql://your-mysql-host:3306/{domain}_db?useSSL=false&serverTimezone=UTC
mysql.username=your_mysql_username
mysql.password=your_mysql_password

å»ºè®®çš„ä½œä¸šé…ç½®ï¼š
- å¹¶è¡Œåº¦: {parallelism}
- Checkpointé—´éš”: 60s
- çŠ¶æ€åç«¯: RocksDB
- é‡å¯ç­–ç•¥: fixed-delay (3æ¬¡ï¼Œ10sé—´éš”)

æ€§èƒ½ä¼˜åŒ–å»ºè®®ï¼š
1. æ ¹æ®æ•°æ®é‡è°ƒæ•´å¹¶è¡Œåº¦
2. ç»´è¡¨ç¼“å­˜TTLæ ¹æ®æ•°æ®æ›´æ–°é¢‘ç‡è°ƒæ•´
3. MySQLè¿æ¥æ± å¤§å°æ ¹æ®å¹¶å‘åº¦è°ƒæ•´
4. å¼€å¯MiniBatchæå‡ååé‡

ç›‘æ§æŒ‡æ ‡å»ºè®®ï¼š
- äº‹ä»¶å¤„ç†TPS
- ç«¯åˆ°ç«¯å»¶è¿Ÿ
- å¤„ç†æˆåŠŸç‡
- CheckpointæˆåŠŸç‡
*/"""
    
    return sql_content

def generate_config_guide(config):
    """ç”Ÿæˆé…ç½®æŒ‡å—"""
    domain = config["domain"]
    job_name = config["job_name"]
    
    guide_content = f"""# {job_name} - é˜¿é‡Œäº‘Flink SQLä½œä¸šé…ç½®æŒ‡å—

## ä½œä¸šä¿¡æ¯
- **ä½œä¸šåç§°**: {job_name}
- **ä¸šåŠ¡åŸŸ**: {domain}
- **ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## 1. å‚æ•°é…ç½®

åœ¨é˜¿é‡Œäº‘Flink SQLä½œä¸šä¸­ï¼Œéœ€è¦é…ç½®ä»¥ä¸‹å‚æ•°ï¼š

### Kafkaé…ç½®
```properties
kafka.input.topic={domain}-events
kafka.bootstrap.servers=your-kafka-cluster:9092
kafka.group.id={domain}-event-processor
```

### MySQLé…ç½®
```properties
mysql.url=jdbc:mysql://your-mysql-host:3306/{domain}_db?useSSL=false&serverTimezone=UTC
mysql.username=your_mysql_username
mysql.password=your_mysql_password
```

## 2. ä½œä¸šé…ç½®å»ºè®®

### åŸºæœ¬é…ç½®
- **ä½œä¸šåç§°**: `{domain}-event-processor`
- **å¹¶è¡Œåº¦**: `{config.get('parallelism', 2)}`
- **Checkpointé—´éš”**: `60s`
- **çŠ¶æ€åç«¯**: `RocksDB`

### é˜¿é‡Œäº‘Flink SQLä½œä¸šé«˜çº§é…ç½®
```yaml
# Checkpointé…ç½®
execution.checkpointing.interval: 60s
execution.checkpointing.timeout: 10min
execution.checkpointing.max-concurrent-checkpoints: 1

# é‡å¯ç­–ç•¥
restart-strategy: fixed-delay
restart-strategy.fixed-delay.attempts: 3
restart-strategy.fixed-delay.delay: 10s

# çŠ¶æ€åç«¯
state.backend: rocksdb
state.backend.incremental: true

# MiniBatchä¼˜åŒ–ï¼ˆé˜¿é‡Œäº‘æ¨èï¼‰
table.exec.mini-batch.enabled: true
table.exec.mini-batch.allow-latency: 1s
table.exec.mini-batch.size: 1000

# ç½‘ç»œé…ç½®
taskmanager.network.memory.fraction: 0.1
taskmanager.network.memory.min: 64mb
taskmanager.network.memory.max: 1gb
```

## 3. éƒ¨ç½²æ­¥éª¤

1. **ç™»å½•é˜¿é‡Œäº‘æ§åˆ¶å°**
   - è®¿é—®å®æ—¶è®¡ç®—Flinkç‰ˆæ§åˆ¶å°
   - é€‰æ‹©å¯¹åº”çš„workspace

2. **åˆ›å»ºSQLä½œä¸š**
   - ç‚¹å‡»"æ–°å»ºä½œä¸š"
   - é€‰æ‹©"SQLä½œä¸š"
   - è¾“å…¥ä½œä¸šåç§°ï¼š`{domain}-event-processor`

3. **é…ç½®ä½œä¸šå‚æ•°**
   - åœ¨"å‚æ•°é…ç½®"ä¸­è®¾ç½®ä¸Šè¿°å‚æ•°
   - é€‰æ‹©åˆé€‚çš„Flinkç‰ˆæœ¬ï¼ˆæ¨è1.15åŠä»¥ä¸Šï¼‰

4. **æäº¤SQLä»£ç **
   - å°†ç”Ÿæˆçš„SQLä»£ç å¤åˆ¶åˆ°ç¼–è¾‘å™¨
   - è¿›è¡Œè¯­æ³•æ£€æŸ¥

5. **èµ„æºé…ç½®**
   - é€‰æ‹©é€‚å½“çš„CUæ•°é‡
   - é…ç½®å¹¶è¡Œåº¦

6. **å¯åŠ¨ä½œä¸š**
   - å…ˆè¿›è¡Œ"è°ƒè¯•è¿è¡Œ"
   - éªŒè¯æ— è¯¯å"å¯åŠ¨"æ­£å¼ä½œä¸š

## 4. ç›‘æ§å’Œè¿ç»´

### å…³é”®ç›‘æ§æŒ‡æ ‡
- **ä¸šåŠ¡æŒ‡æ ‡**: äº‹ä»¶å¤„ç†TPSã€ç«¯åˆ°ç«¯å»¶è¿Ÿã€å¤„ç†æˆåŠŸç‡
- **æŠ€æœ¯æŒ‡æ ‡**: CPUä½¿ç”¨ç‡ã€å†…å­˜ä½¿ç”¨ç‡ã€CheckpointæˆåŠŸç‡
- **é˜¿é‡Œäº‘ç‰¹æœ‰æŒ‡æ ‡**: ä½œä¸šå¥åº·åº¦ã€èƒŒå‹çŠ¶æ€ã€èµ„æºåˆ©ç”¨ç‡

### å‘Šè­¦è®¾ç½®
åœ¨é˜¿é‡Œäº‘äº‘ç›‘æ§ä¸­è®¾ç½®ä»¥ä¸‹å‘Šè­¦ï¼š
- äº‹ä»¶å¤„ç†å»¶è¿Ÿ > 30s
- å¤„ç†å¤±è´¥ç‡ > 5%
- Checkpointå¤±è´¥ç‡ > 10%
- ä½œä¸šçŠ¶æ€å¼‚å¸¸

### æ€§èƒ½ä¼˜åŒ–
1. **å¹¶è¡Œåº¦è°ƒä¼˜**: æ ¹æ®Kafkaåˆ†åŒºæ•°å’Œæ•°æ®é‡è°ƒæ•´
2. **å†…å­˜è°ƒä¼˜**: æ ¹æ®çŠ¶æ€å¤§å°è°ƒæ•´TaskManagerå†…å­˜
3. **ç»´è¡¨ä¼˜åŒ–**: è°ƒæ•´ç¼“å­˜å¤§å°å’ŒTTL
4. **æ‰¹é‡ä¼˜åŒ–**: å¼€å¯MiniBatchæå‡ååé‡

## 5. æ•…éšœæ’æŸ¥

### å¸¸è§é—®é¢˜
1. **ç»´è¡¨æŸ¥è¯¢è¶…æ—¶**: æ£€æŸ¥MySQLè¿æ¥å’Œç´¢å¼•
2. **Kafkaæ¶ˆè´¹å»¶è¿Ÿ**: æ£€æŸ¥å¹¶è¡Œåº¦å’Œåˆ†åŒºå‡è¡¡
3. **å†…å­˜ä¸è¶³**: è°ƒæ•´èµ„æºé…ç½®æˆ–ä¼˜åŒ–SQL
4. **Checkpointå¤±è´¥**: æ£€æŸ¥çŠ¶æ€åç«¯é…ç½®

### æ—¥å¿—æŸ¥çœ‹
- åœ¨é˜¿é‡Œäº‘æ§åˆ¶å°æŸ¥çœ‹ä½œä¸šè¿è¡Œæ—¥å¿—
- å…³æ³¨ERRORå’ŒWARNçº§åˆ«çš„æ—¥å¿—
- ä½¿ç”¨é“¾è·¯è¿½è¸ªå®šä½é—®é¢˜

å‚è€ƒæ–‡æ¡£: https://help.aliyun.com/zh/flink/realtime-flink/
"""
    
    return guide_content

def main():
    if len(sys.argv) != 2:
        print("ä½¿ç”¨æ–¹æ³•: python3 simple-sql-generator.py <config.json>")
        print("é…ç½®æ–‡ä»¶ç¤ºä¾‹è¯·å‚è€ƒ: examples/user-job-config.json")
        sys.exit(1)
    
    config_file = sys.argv[1]
    if not os.path.exists(config_file):
        print(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_file}")
        sys.exit(1)
    
    try:
        # åŠ è½½é…ç½®æ–‡ä»¶
        with open(config_file, 'r', encoding='utf-8') as f:
            config = json.load(f)
        
        domain = config["domain"]
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        output_dir = f"generated/sql/{domain}"
        os.makedirs(output_dir, exist_ok=True)
        
        # ç”ŸæˆSQLæ–‡ä»¶
        sql_content = generate_aliyun_flink_sql(config)
        sql_file = os.path.join(output_dir, f"{domain}-flink-job.sql")
        with open(sql_file, 'w', encoding='utf-8') as f:
            f.write(sql_content)
        
        # ç”Ÿæˆé…ç½®æŒ‡å—
        guide_content = generate_config_guide(config)
        guide_file = os.path.join(output_dir, f"{domain}-é…ç½®æŒ‡å—.md")
        with open(guide_file, 'w', encoding='utf-8') as f:
            f.write(guide_content)
        
        print("\n" + "="*60)
        print("ğŸ‰ é˜¿é‡Œäº‘Flink SQLä½œä¸šç”ŸæˆæˆåŠŸï¼")
        print("="*60)
        print(f"ğŸ“ SQLæ–‡ä»¶: {sql_file}")
        print(f"ğŸ“ é…ç½®æŒ‡å—: {guide_file}")
        print("\nğŸ“‹ ä¸‹ä¸€æ­¥æ“ä½œ:")
        print("1. ç™»å½•é˜¿é‡Œäº‘å®æ—¶è®¡ç®—Flinkç‰ˆæ§åˆ¶å°")
        print("2. åˆ›å»ºæ–°çš„SQLä½œä¸š")
        print("3. å¤åˆ¶ç”Ÿæˆçš„SQLå†…å®¹åˆ°ç¼–è¾‘å™¨")
        print("4. å‚è€ƒé…ç½®æŒ‡å—è®¾ç½®ä½œä¸šå‚æ•°")
        print("5. è°ƒè¯•è¿è¡Œå¹¶å¯åŠ¨ä½œä¸š")
        print("\nğŸ”— å‚è€ƒæ–‡æ¡£: https://help.aliyun.com/zh/flink/realtime-flink/")
        
    except Exception as e:
        print(f"ç”Ÿæˆå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

if __name__ == "__main__":
    main()
