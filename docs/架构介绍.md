# Flink实时计算项目架构介绍

## 1. 项目概述

本项目是基于Apache Flink的实时计算脚手架，专门用于处理业务域事件驱动的实时数据流。项目采用事件驱动架构，支持多种业务类型的事件处理，并提供了DataStream API和Flink SQL两种开发模式。

## 2. 核心架构

### 2.1 整体架构图

```
┌─────────────┐    ┌──────────────┐    ┌─────────────┐    ┌──────────────┐
│  业务系统    │───▶│   Kafka      │───▶│   Flink     │───▶│   MySQL      │
│             │    │   事件总线    │    │   计算引擎   │    │   宽表存储    │
└─────────────┘    └──────────────┘    └─────────────┘    └──────────────┘
                                               │
                                               ▼
                                        ┌─────────────┐
                                        │   MySQL     │
                                        │   维度表     │
                                        └─────────────┘
```

### 2.2 数据流向

1. **业务系统** → **Kafka事件总线**：业务系统发送统一格式的事件消息
2. **Kafka** → **Flink计算引擎**：Flink消费Kafka中的事件数据
3. **Flink** ↔ **MySQL维度表**：关联维度数据进行数据丰富化
4. **Flink** → **MySQL宽表**：将处理后的结果写入业务宽表

## 3. 数据模型设计

### 3.1 统一事件模型（BusinessEvent）

```json
{
  "domain": "user",           // 业务域
  "type": "user_login",       // 事件类型
  "timestamp": 1642567890000, // 事件时间戳
  "eventId": "uuid-123",      // 事件唯一ID
  "payload": {                // 载荷数据
    "userId": "user123",
    "loginTime": 1642567890000,
    "device": "mobile",
    "ip": "192.168.1.1"
  },
  "version": "1.0",           // 数据版本
  "source": "user-service"    // 来源系统
}
```

### 3.2 事件分类

- **用户域事件**：`user_login`、`user_purchase`、`user_view`
- **订单域事件**：`order_create`、`order_pay`、`order_cancel`
- **商品域事件**：`product_view`、`product_search`、`product_recommend`

## 4. 技术架构

### 4.1 核心组件

| 组件 | 说明 | 技术栈 |
|------|------|--------|
| **事件总线** | 消息队列和事件分发 | Apache Kafka |
| **计算引擎** | 实时流计算处理 | Apache Flink |
| **维度存储** | 维度数据存储 | MySQL |
| **结果存储** | 宽表数据存储 | MySQL |

### 4.2 核心类结构

```
com.flink.realtime
├── app/                    # 应用程序入口
│   ├── BusinessDataStreamApp.java   # DataStream API应用
│   └── BusinessSqlApp.java          # Flink SQL应用
├── bean/                   # 数据模型
│   ├── BaseBean.java       # 基础数据对象
│   └── BusinessEvent.java  # 业务事件模型
├── processor/              # 事件处理器
│   ├── EventProcessor.java          # 处理器接口
│   ├── EventProcessorFactory.java   # 处理器工厂
│   └── impl/
│       └── UserEventProcessor.java  # 用户事件处理器
├── source/                 # 数据源
│   └── MySQLDimSource.java  # MySQL维表数据源
├── sink/                   # 数据输出
│   └── MySQLSinkFunction.java # MySQL结果输出
├── function/               # UDF和序列化
│   └── BusinessEventDeserializationSchema.java
├── common/                 # 通用工具
│   └── FlinkUtils.java     # Flink环境配置
└── util/                   # 工具类
    └── ConfigUtils.java    # 配置管理
```

## 5. 处理模式

### 5.1 DataStream API模式

- **优势**：灵活性高，可以实现复杂的业务逻辑
- **适用场景**：复杂的状态管理、自定义窗口操作、复杂的数据关联
- **关键特性**：
  - 支持状态管理
  - 支持广播流进行维表关联
  - 支持自定义事件处理器

### 5.2 Flink SQL模式

- **优势**：开发简单，SQL语法易懂
- **适用场景**：标准的ETL操作、简单的数据关联和聚合
- **关键特性**：
  - 声明式SQL开发
  - 支持维表Lookup Join
  - 支持标准SQL函数

## 6. 关键特性

### 6.1 事件驱动架构

- **统一事件模型**：所有业务事件采用统一的数据格式
- **类型化处理**：根据事件类型路由到不同的处理逻辑
- **可扩展性**：新增业务类型只需实现对应的事件处理器

### 6.2 维表关联

- **实时关联**：支持与MySQL维表进行实时关联
- **缓存机制**：维表数据支持本地缓存，提高查询性能
- **定时刷新**：维表数据支持定时刷新，保证数据一致性

### 6.3 容错机制

- **Checkpoint**：支持Flink Checkpoint机制，保证数据一致性
- **重启策略**：配置自动重启策略，提高系统可用性
- **异常处理**：完善的异常处理机制，避免数据丢失

## 7. 配置管理

### 7.1 核心配置项

```properties
# Kafka配置
kafka.bootstrap.servers=localhost:9092
kafka.input.topic=business-events
kafka.group.id=flink-consumer-group

# MySQL配置
mysql.url=jdbc:mysql://localhost:3306/flink_db
mysql.username=root
mysql.password=root

# Flink配置
flink.parallelism=1
flink.checkpoint.interval=5000
```

### 7.2 环境区分

- **开发环境**：本地开发调试配置
- **测试环境**：功能测试和集成测试配置
- **生产环境**：生产环境高可用配置

## 8. 部署架构

### 8.1 单机部署

- 适用于开发和测试环境
- 所有组件部署在单台服务器上
- 使用Docker Compose进行容器化部署

### 8.2 集群部署

- 适用于生产环境
- Kafka集群 + Flink集群 + MySQL主从
- 支持水平扩展和高可用

## 9. 监控告警

### 9.1 关键指标

- **吞吐量**：每秒处理事件数量
- **延迟**：事件处理端到端延迟
- **成功率**：事件处理成功率
- **资源使用**：CPU、内存、网络使用率

### 9.2 告警策略

- **业务告警**：处理失败率超过阈值
- **性能告警**：延迟超过SLA要求
- **资源告警**：资源使用率过高

## 10. 扩展指南

### 10.1 新增事件类型

1. 定义事件数据结构
2. 实现EventProcessor接口
3. 在EventProcessorFactory中注册
4. 配置对应的维表和结果表

### 10.2 新增数据源

1. 实现对应的Source Function
2. 配置数据源连接参数
3. 添加到应用程序中

### 10.3 新增输出目标

1. 实现对应的Sink Function
2. 配置输出目标连接参数
3. 添加到应用程序中
