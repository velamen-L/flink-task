# 错题本宽表混合架构使用指南

## 🎯 概述

本文档详细介绍了错题本实时宽表的混合架构实现，基于**AI编程脚手架 + 动态路由 + 阿里云Catalog**的现代化架构，支持快速开发、热部署和灵活扩展。

## 🏗️ 架构设计

### 整体架构图
```
┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐
│   业务系统      │    │   Kafka集群     │    │   Flink集群     │
│                │    │                │    │                │
│ ┌─────────────┐ │    │ ┌─────────────┐ │    │ ┌─────────────┐ │
│ │ 错题本      │ │───▶│ │ wrongbook-  │ │───▶│ │ 事件源      │ │
│ │ 业务事件    │ │    │ │ events      │ │    │ │ KafkaSource │ │
│ └─────────────┘ │    └─────────────────┘    │ └─────────────┘ │
└─────────────────┘                           │                │
                                              │ ┌─────────────┐ │
                                              │ │ 动态路由    │ │
                                              │ │ 配置源      │ │
                                              │ │ MySQL       │ │
                                              │ └─────────────┘ │
                                              │                │
                                              │ ┌─────────────┐ │
                                              │ │ 动态路由    │ │
                                              │ │ 处理器      │ │
                                              │ └─────────────┘ │
                                              │                │
                                              │ ┌─────────────┐ │
                                              │ │ 维表关联    │ │
                                              │ │ Broadcast   │ │
                                              │ └─────────────┘ │
                                              └─────────────────┘
                                                       │
                                                       ▼
                                              ┌─────────────────┐
                                              │   数据输出      │
                                              │                │
                                              │ ┌─────────────┐ │
                                              │ │ MySQL宽表   │ │
                                              │ │ 主流输出    │ │
                                              │ └─────────────┘ │
                                              │                │
                                              │ ┌─────────────┐ │
                                              │ │ 告警Topic   │ │
                                              │ │ 侧流输出    │ │
                                              │ └─────────────┘ │
                                              │                │
                                              │ ┌─────────────┐ │
                                              │ │ 指标Topic   │ │
                                              │ │ 侧流输出    │ │
                                              │ └─────────────┘ │
                                              └─────────────────┘
```

### 核心组件

#### 1. 事件源层
- **Kafka Topic**: `wrongbook-events` - 统一的事件存储
- **事件格式**: 标准化的`BusinessEvent`格式
- **事件类型**: `wrongbook_add`, `wrongbook_fix`, `wrongbook_delete`

#### 2. 处理层
- **动态路由**: 基于配置的事件类型路由
- **处理器**: 可插拔的业务逻辑处理器
- **维表关联**: 基于Broadcast State的维表关联

#### 3. 输出层
- **主流输出**: MySQL宽表 `dwd_wrong_record_wide_delta`
- **侧流输出**: 告警和指标Topic

## 📊 数据模型

### 1. 事件数据模型

#### BusinessEvent结构
```json
{
  "domain": "wrongbook",
  "type": "wrongbook_add",
  "timestamp": 1640995200000,
  "eventId": "evt_123456",
  "payload": {
    "userId": "user_123",
    "questionId": "q_456",
    "subject": "math",
    "subjectName": "数学",
    "patternId": "pattern_789",
    "chapterId": "chapter_001",
    "chapterName": "二次函数",
    "wrongTime": 1640995200000,
    "createTime": 1640995100000
  }
}
```

#### 事件类型定义

##### wrongbook_add (错题添加事件)
```json
{
  "type": "wrongbook_add",
  "description": "错题添加事件",
  "payload_fields": [
    {"name": "userId", "type": "String", "required": true},
    {"name": "questionId", "type": "String", "required": true},
    {"name": "subject", "type": "String", "required": false},
    {"name": "subjectName", "type": "String", "required": false},
    {"name": "patternId", "type": "String", "required": false},
    {"name": "chapterId", "type": "String", "required": false},
    {"name": "chapterName", "type": "String", "required": false},
    {"name": "wrongTime", "type": "Long", "required": false},
    {"name": "createTime", "type": "Long", "required": false}
  ]
}
```

##### wrongbook_fix (错题订正事件)
```json
{
  "type": "wrongbook_fix",
  "description": "错题订正事件",
  "payload_fields": [
    {"name": "userId", "type": "String", "required": true},
    {"name": "questionId", "type": "String", "required": true},
    {"name": "wrongRecordId", "type": "String", "required": true},
    {"name": "fixTime", "type": "Long", "required": true},
    {"name": "fixResult", "type": "String", "required": true},
    {"name": "attempts", "type": "Integer", "required": false},
    {"name": "timeCost", "type": "Long", "required": false}
  ]
}
```

### 2. 维表数据模型

#### tower_pattern (题目模式维表)
```sql
CREATE TABLE tower_pattern (
    id VARCHAR(50) PRIMARY KEY,
    name VARCHAR(100),
    type INT,
    subject VARCHAR(20),
    difficulty DECIMAL(5,3),
    modify_time TIMESTAMP
);
```

#### tower_teaching_type_pt (教学类型关联维表)
```sql
CREATE TABLE tower_teaching_type_pt (
    id BIGINT PRIMARY KEY,
    teaching_type_id BIGINT,
    pt_id VARCHAR(50),
    order_num INT,
    is_delete TINYINT,
    modify_time TIMESTAMP
);
```

#### tower_teaching_type (教学类型维表)
```sql
CREATE TABLE tower_teaching_type (
    id BIGINT PRIMARY KEY,
    chapter_id VARCHAR(50),
    teaching_type_name VARCHAR(100),
    is_delete TINYINT,
    modify_time TIMESTAMP
);
```

### 3. 结果表数据模型

#### dwd_wrong_record_wide_delta (错题宽表)
```sql
CREATE TABLE dwd_wrong_record_wide_delta (
    id BIGINT PRIMARY KEY,
    wrong_id VARCHAR(50),
    user_id VARCHAR(50),
    subject VARCHAR(20),
    subject_name VARCHAR(50),
    question_id VARCHAR(50),
    question TEXT,
    pattern_id VARCHAR(50),
    pattern_name VARCHAR(100),
    teach_type_id VARCHAR(50),
    teach_type_name VARCHAR(100),
    collect_time TIMESTAMP,
    fix_id VARCHAR(50),
    fix_time TIMESTAMP,
    fix_result BIGINT,
    fix_result_desc VARCHAR(50),
    event_id VARCHAR(100),
    event_type VARCHAR(50),
    process_time TIMESTAMP
);
```

## 🔄 处理流程

### 1. 事件处理流程

```
事件接收 → 动态路由 → 业务处理 → 维表关联 → 数据输出
    │           │           │           │           │
    │           │           │           │           └── MySQL宽表
    │           │           │           └── 维表数据关联
    │           │           └── 处理器执行
    │           └── 路由配置查询
    └── Kafka事件
```

### 2. 动态路由机制

#### 路由配置表结构
```sql
CREATE TABLE flink_routing_config (
    id BIGINT PRIMARY KEY AUTO_INCREMENT,
    event_type VARCHAR(100),
    processor_class VARCHAR(200),
    enabled TINYINT DEFAULT 1,
    hot_deployable TINYINT DEFAULT 1,
    priority INT DEFAULT 100,
    version VARCHAR(20),
    create_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    update_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP
);
```

#### 路由配置示例
```sql
INSERT INTO flink_routing_config (event_type, processor_class, enabled, hot_deployable, priority, version) VALUES
('wrongbook_add', 'com.flink.realtime.processor.impl.WrongbookAddProcessor', 1, 1, 100, '1.0'),
('wrongbook_fix', 'com.flink.realtime.processor.impl.WrongbookFixProcessor', 1, 1, 100, '1.0'),
('wrongbook_delete', 'com.flink.realtime.processor.impl.WrongbookDeleteProcessor', 0, 1, 90, '1.0');
```

### 3. 维表关联机制

#### 维表关联流程
```
主数据流 → 维表状态查询 → 数据关联 → 丰富数据 → 输出
    │           │              │           │           │
    │           │              │           │           └── 完整宽表数据
    │           │              │           └── 业务字段补充
    │           │              └── 维表数据关联
    │           └── Broadcast State
    └── 业务事件数据
```

#### 维表刷新机制
- **刷新间隔**: 30分钟
- **刷新方式**: 全量刷新
- **状态管理**: Broadcast State

## 🚀 开发指南

### 1. 环境准备

#### 依赖配置
```xml
<dependencies>
    <!-- Flink Core -->
    <dependency>
        <groupId>org.apache.flink</groupId>
        <artifactId>flink-streaming-java</artifactId>
        <version>${flink.version}</version>
    </dependency>
    
    <!-- Flink Kafka Connector -->
    <dependency>
        <groupId>org.apache.flink</groupId>
        <artifactId>flink-connector-kafka</artifactId>
        <version>${flink.version}</version>
    </dependency>
    
    <!-- MySQL Connector -->
    <dependency>
        <groupId>mysql</groupId>
        <artifactId>mysql-connector-java</artifactId>
        <version>8.0.28</version>
    </dependency>
    
    <!-- JSON Processing -->
    <dependency>
        <groupId>com.fasterxml.jackson.core</groupId>
        <artifactId>jackson-databind</artifactId>
        <version>2.13.0</version>
    </dependency>
</dependencies>
```

#### 配置文件
```properties
# Kafka配置
kafka.bootstrap.servers=localhost:9092
kafka.group.id=wrongbook-wide-table-group
kafka.username=
kafka.password=

# MySQL配置
mysql.url=jdbc:mysql://localhost:3306/dwd
mysql.username=root
mysql.password=password
mysql.driver=com.mysql.cj.jdbc.Driver

# Flink配置
flink.parallelism=2
flink.checkpoint.interval=10000
```

### 2. 业务应用开发

#### 使用AI生成器
```bash
# 生成错题本应用
python scripts/ai-job-generator.py scripts/examples/wrongbook-wide-table-config.json

# 生成的Java文件位置
src/main/java/com/flink/realtime/business/WrongbookWideTableApp.java
```

#### 手动开发步骤
1. **创建业务应用类**
2. **配置事件源**
3. **实现动态路由**
4. **添加维表关联**
5. **配置数据输出**

### 3. 处理器开发

#### 处理器接口
```java
public interface EventProcessor {
    Object process(BusinessEvent event) throws Exception;
}
```

#### 处理器实现示例
```java
public class WrongbookAddProcessor implements EventProcessor {
    
    @Override
    public Object process(BusinessEvent event) throws Exception {
        // 1. 验证事件
        validateEvent(event);
        
        // 2. 提取数据
        Map<String, Object> data = extractData(event);
        
        // 3. 业务处理
        processBusinessLogic(data);
        
        // 4. 返回结果
        return data;
    }
    
    private void validateEvent(BusinessEvent event) {
        // 事件验证逻辑
        if (event.getPayload() == null) {
            throw new IllegalArgumentException("事件payload不能为空");
        }
    }
    
    private Map<String, Object> extractData(BusinessEvent event) {
        Map<String, Object> data = new HashMap<>();
        JsonNode payload = event.getPayload();
        
        data.put("userId", payload.get("userId").asText());
        data.put("questionId", payload.get("questionId").asText());
        data.put("subject", payload.get("subject").asText());
        // ... 其他字段提取
        
        return data;
    }
    
    private void processBusinessLogic(Map<String, Object> data) {
        // 业务处理逻辑
        // 例如：数据转换、业务规则验证等
    }
}
```

## 🔧 部署指南

### 1. 本地开发环境

#### 启动Kafka
```bash
# 启动Zookeeper
bin/zookeeper-server-start.sh config/zookeeper.properties

# 启动Kafka
bin/kafka-server-start.sh config/server.properties

# 创建Topic
bin/kafka-topics.sh --create --topic wrongbook-events --bootstrap-server localhost:9092 --partitions 3 --replication-factor 1
```

#### 启动MySQL
```bash
# 启动MySQL服务
sudo systemctl start mysql

# 创建数据库和表
mysql -u root -p
CREATE DATABASE dwd;
USE dwd;
-- 执行建表SQL
```

#### 运行Flink作业
```bash
# 编译打包
mvn clean package -DskipTests

# 提交作业
$FLINK_HOME/bin/flink run \
  --class com.flink.realtime.business.WrongbookWideTableApp \
  target/flink-task-1.0-SNAPSHOT.jar wrongbook
```

### 2. 生产环境部署

#### 阿里云VVP平台
1. **创建项目**: 在VVP控制台创建新项目
2. **上传JAR**: 上传编译好的JAR包
3. **配置作业**: 配置作业参数和资源配置
4. **启动作业**: 启动Flink作业

#### Kubernetes部署
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: wrongbook-wide-table
spec:
  replicas: 1
  selector:
    matchLabels:
      app: wrongbook-wide-table
  template:
    metadata:
      labels:
        app: wrongbook-wide-table
    spec:
      containers:
      - name: flink-jobmanager
        image: flink:1.17
        ports:
        - containerPort: 8081
        command: ["/opt/flink/bin/jobmanager.sh"]
        env:
        - name: FLINK_PROPERTIES
          value: "jobmanager.rpc.address: wrongbook-wide-table"
```

## 📊 监控和运维

### 1. 监控指标

#### 关键指标
- **事件处理速率**: 每秒处理事件数
- **处理延迟**: 事件从接收到处理的时间
- **错误率**: 处理失败的事件比例
- **状态大小**: 内存中状态数据大小

#### 监控配置
```properties
# 监控配置
metrics.reporter.prom.class=org.apache.flink.metrics.prometheus.PrometheusReporter
metrics.reporter.prom.port=9249
```

### 2. 告警规则

#### 告警配置
```yaml
alerts:
  - name: "处理延迟过高"
    condition: "processing_latency > 30s"
    severity: "critical"
    
  - name: "错误率过高"
    condition: "error_rate > 1%"
    severity: "warning"
    
  - name: "状态大小异常"
    condition: "state_size > 1GB"
    severity: "warning"
```

### 3. 故障处理

#### 常见问题
1. **事件处理失败**: 检查事件格式和处理器逻辑
2. **维表关联失败**: 检查维表连接和查询SQL
3. **输出失败**: 检查MySQL连接和表结构

#### 故障恢复
1. **配置回滚**: 通过配置源回滚到稳定版本
2. **作业重启**: 重启Flink作业
3. **数据修复**: 重新处理失败的数据

## 🔄 扩展指南

### 1. 添加新事件类型

#### 步骤1: 更新配置
```json
{
  "event_type": "wrongbook_review",
  "processor_class": "com.flink.realtime.processor.impl.WrongbookReviewProcessor",
  "enabled": true,
  "hot_deployable": true,
  "priority": 100
}
```

#### 步骤2: 开发处理器
```java
public class WrongbookReviewProcessor implements EventProcessor {
    @Override
    public Object process(BusinessEvent event) throws Exception {
        // 实现新的业务逻辑
    }
}
```

#### 步骤3: 热部署
```sql
INSERT INTO flink_routing_config (event_type, processor_class, enabled, hot_deployable, priority, version) 
VALUES ('wrongbook_review', 'com.flink.realtime.processor.impl.WrongbookReviewProcessor', 1, 1, 100, '1.0');
```

### 2. 添加新维表

#### 步骤1: 创建维表
```sql
CREATE TABLE new_dimension_table (
    id VARCHAR(50) PRIMARY KEY,
    name VARCHAR(100),
    -- 其他字段
);
```

#### 步骤2: 更新配置
```json
{
  "name": "new_dimension_table",
  "type": "mysql",
  "key_field": "id",
  "query_sql": "SELECT * FROM new_dimension_table",
  "refresh_interval": "30m"
}
```

#### 步骤3: 修改应用代码
```java
// 添加新的维表关联逻辑
```

## 🎉 总结

错题本宽表混合架构通过以下特性实现了高效、灵活的实时数据处理：

1. **事件驱动**: 基于Kafka的统一事件存储和分发
2. **动态路由**: 支持新事件类型的热部署
3. **维表关联**: 基于Broadcast State的高效维表关联
4. **AI生成**: 基于配置的代码自动生成
5. **监控完善**: 全面的监控和告警机制

这套架构为错题本业务提供了完整的实时数据处理解决方案，支持业务的快速发展和技术的持续演进。
