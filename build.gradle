plugins {
    id 'java'
    id 'maven-publish'
}

group = 'com.flink.realtime'
version = '1.0.0'

java {
    sourceCompatibility = JavaVersion.VERSION_17
    targetCompatibility = JavaVersion.VERSION_17
}

repositories {
    mavenCentral()
    maven {
        url 'https://repo1.maven.org/maven2'
    }
}

dependencies {
    // Flink dependencies
    implementation 'org.apache.flink:flink-streaming-java:1.18.0'
    implementation 'org.apache.flink:flink-table-api-java-bridge:1.18.0'
    implementation 'org.apache.flink:flink-table-runtime:1.18.0'
    implementation 'org.apache.flink:flink-clients:1.18.0'
    
    // Connector dependencies
    implementation 'org.apache.flink:flink-connector-kafka:1.18.0'
    implementation 'org.apache.flink:flink-connector-jdbc:3.1.1-1.18'
    implementation 'mysql:mysql-connector-java:8.0.33'
    
    // JSON processing
    implementation 'com.fasterxml.jackson.core:jackson-databind:2.15.2'
    implementation 'com.fasterxml.jackson.dataformat:jackson-dataformat-yaml:2.15.2'
    
    // Logging
    implementation 'org.slf4j:slf4j-api:1.7.36'
    implementation 'org.apache.logging.log4j:log4j-slf4j-impl:2.20.0'
    
    // Test dependencies
    testImplementation 'junit:junit:4.13.2'
    testImplementation 'org.apache.flink:flink-test-utils:1.18.0'
}

// =============================================================================
// AIå·¥ä½œæµä»»åŠ¡é…ç½®
// =============================================================================

// AIå·¥ä½œæµé…ç½®
ext.aiWorkflowConfig = [
    workspaceDir: 'job',
    aiProvider: 'cursor',
    rulesDir: '.cursor/rules',
    outputDir: 'build/ai-workflow',
    minQualityScore: 85,
    qualityGateMode: 'strict',
    enableDetailedReports: true
]

// AIå·¥ä½œæµä»»åŠ¡ç»„
def AI_TASK_GROUP = 'flink-ai'

// 1. ç«¯åˆ°ç«¯AIå·¥ä½œæµä»»åŠ¡
task runAiWorkflow {
    group AI_TASK_GROUP
    description 'æ‰§è¡Œå®Œæ•´çš„AIé©±åŠ¨ç«¯åˆ°ç«¯å·¥ä½œæµ (SQLç”Ÿæˆ â†’ éªŒè¯ â†’ ERçŸ¥è¯†åº“æ›´æ–°)'
    
    doLast {
        println """
        ğŸš€ æ‰§è¡ŒAIé©±åŠ¨ç«¯åˆ°ç«¯å·¥ä½œæµ
        
        å·¥ä½œç©ºé—´: ${aiWorkflowConfig.workspaceDir}
        AIæä¾›è€…: ${aiWorkflowConfig.aiProvider}
        è´¨é‡æ ‡å‡†: ${aiWorkflowConfig.minQualityScore}åˆ†
        è¾“å‡ºç›®å½•: ${aiWorkflowConfig.outputDir}
        
        âš ï¸  æ³¨æ„: å½“å‰ä¸ºæ¨¡æ‹Ÿæ¨¡å¼ï¼Œå®é™…çš„AIå·¥ä½œæµéœ€è¦é€šè¿‡Cursor AIæ‰§è¡Œ
        
        è¯·åœ¨Cursorä¸­ä½¿ç”¨ä»¥ä¸‹æç¤ºè¯ï¼š
        ================================================
        è¯·åŸºäº intelligent-end-to-end-workflow.mdc è§„åˆ™æ‰§è¡Œå®Œæ•´çš„ç«¯åˆ°ç«¯å·¥ä½œæµï¼Œ
        å¤„ç† job/wrongbook/wrongbook-request-v3.md æ–‡ä»¶ã€‚

        è¯·æŒ‰ç…§ä»¥ä¸‹é¡ºåºæ‰§è¡Œï¼š
        1. é˜¶æ®µ1ï¼šåŸºäº intelligent-sql-job-generator.mdc ç”Ÿæˆ Flink SQL
        2. é˜¶æ®µ2ï¼šåŸºäº intelligent-validation-workflow.mdc è¿›è¡Œæ•°æ®éªŒè¯
        3. é˜¶æ®µ3ï¼šåŸºäº intelligent-er-knowledge-base.mdc æ›´æ–°ERçŸ¥è¯†åº“

        ç”Ÿæˆå®Œæ•´çš„æ‰§è¡ŒæŠ¥å‘Šï¼ŒåŒ…æ‹¬è´¨é‡è¯„åˆ†å’Œéƒ¨ç½²å»ºè®®ã€‚
        ================================================
        """
        
        // åˆ›å»ºè¾“å‡ºç›®å½•
        mkdir "${aiWorkflowConfig.outputDir}"
        
        // å‘ç°requestæ–‡ä»¶
        def requestFiles = fileTree(aiWorkflowConfig.workspaceDir) {
            include '**/*-request-v3.md'
        }
        
        if (requestFiles.isEmpty()) {
            println "âŒ æœªæ‰¾åˆ°requestæ–‡ä»¶ (*-request-v3.md)"
            println "è¯·ç¡®ä¿åœ¨ ${aiWorkflowConfig.workspaceDir} ç›®å½•ä¸‹æœ‰æ­£ç¡®çš„requestæ–‡ä»¶"
        } else {
            println "ğŸ“ å‘ç°ä»¥ä¸‹requestæ–‡ä»¶ï¼š"
            requestFiles.each { file ->
                def relativePath = rootProject.relativePath(file)
                println "   - ${relativePath}"
            }
            
            println """
            
            âœ… ç¯å¢ƒæ£€æŸ¥å®Œæˆï¼
            ğŸ“‹ è¯·ä½¿ç”¨ä¸Šè¿°æç¤ºè¯åœ¨Cursorä¸­æ‰§è¡ŒAIå·¥ä½œæµ
            """
        }
    }
}

// 2. SQLç”Ÿæˆä»»åŠ¡
task generateFlinkSql {
    group AI_TASK_GROUP
    description 'åŸºäºrequestæ–‡ä»¶æ™ºèƒ½ç”ŸæˆFlink SQL'
    
    doLast {
        println """
        ğŸ“ é˜¶æ®µ1: Flink SQLæ™ºèƒ½ç”Ÿæˆ
        
        è¯·åœ¨Cursorä¸­ä½¿ç”¨ä»¥ä¸‹æç¤ºè¯ï¼š
        ================================================
        è¯·åŸºäº intelligent-sql-job-generator.mdc è§„åˆ™ï¼Œ
        å¤„ç† job/wrongbook/wrongbook-request-v3.md æ–‡ä»¶ï¼Œ
        ç”Ÿæˆä¼˜åŒ–çš„Flink SQLä»£ç ã€‚
        ================================================
        """
    }
}

// 3. æ•°æ®éªŒè¯ä»»åŠ¡
task validateFlinkSql {
    group AI_TASK_GROUP
    description 'å¯¹ç”Ÿæˆçš„Flink SQLè¿›è¡Œå¤šç»´åº¦è´¨é‡éªŒè¯'
    
    doLast {
        println """
        ğŸ” é˜¶æ®µ2: æ•°æ®éªŒè¯
        
        è¯·åœ¨Cursorä¸­ä½¿ç”¨ä»¥ä¸‹æç¤ºè¯ï¼š
        ================================================
        è¯·åŸºäº intelligent-validation-workflow.mdc è§„åˆ™ï¼Œ
        å¯¹ job/wrongbook/sql/wrongbook_wide_table_v3.sql æ–‡ä»¶
        è¿›è¡Œå…¨é¢çš„è´¨é‡éªŒè¯å’Œè¯„åˆ†ã€‚
        ================================================
        """
    }
}

// 4. ERçŸ¥è¯†åº“æ›´æ–°ä»»åŠ¡
task updateErKnowledgeBase {
    group AI_TASK_GROUP
    description 'æ›´æ–°ERå›¾çŸ¥è¯†åº“å¹¶æ£€æµ‹å†²çª'
    
    doLast {
        println """
        ğŸ—„ï¸ é˜¶æ®µ3: ERçŸ¥è¯†åº“æ›´æ–°
        
        è¯·åœ¨Cursorä¸­ä½¿ç”¨ä»¥ä¸‹æç¤ºè¯ï¼š
        ================================================
        è¯·åŸºäº intelligent-er-knowledge-base.mdc è§„åˆ™ï¼Œ
        å¤„ç† job/wrongbook/wrongbook-request-v3.md æ–‡ä»¶ï¼Œ
        æ›´æ–°ERå›¾çŸ¥è¯†åº“å¹¶æ£€æµ‹å†²çªã€‚
        ================================================
        """
    }
}

// 5. ç¯å¢ƒæ£€æŸ¥ä»»åŠ¡
task checkAiEnvironment {
    group AI_TASK_GROUP
    description 'æ£€æŸ¥AIå·¥ä½œæµç¯å¢ƒå’Œä¾èµ–'
    
    doLast {
        println "ğŸ” AIå·¥ä½œæµç¯å¢ƒæ£€æŸ¥"
        println "=" * 50
        
        // æ£€æŸ¥å·¥ä½œç©ºé—´
        def workspaceDir = file(aiWorkflowConfig.workspaceDir)
        println "ğŸ“ å·¥ä½œç©ºé—´: ${workspaceDir.absolutePath}"
        println "   å­˜åœ¨: ${workspaceDir.exists() ? 'âœ…' : 'âŒ'}"
        
        // æ£€æŸ¥è§„åˆ™æ–‡ä»¶ç›®å½•
        def rulesDir = file(aiWorkflowConfig.rulesDir)
        println "ğŸ“‹ è§„åˆ™ç›®å½•: ${rulesDir.absolutePath}"
        println "   å­˜åœ¨: ${rulesDir.exists() ? 'âœ…' : 'âŒ'}"
        
        if (rulesDir.exists()) {
            def ruleFiles = fileTree(rulesDir) {
                include '*.mdc'
            }
            println "   è§„åˆ™æ–‡ä»¶æ•°é‡: ${ruleFiles.files.size()}"
            ruleFiles.each { file ->
                println "   - ${file.name}"
            }
        }
        
        // æ£€æŸ¥requestæ–‡ä»¶
        if (workspaceDir.exists()) {
            def requestFiles = fileTree(workspaceDir) {
                include '**/*-request-v3.md'
            }
            println "ğŸ“ Requestæ–‡ä»¶: ${requestFiles.files.size()}ä¸ª"
            requestFiles.each { file ->
                def relativePath = rootProject.relativePath(file)
                println "   - ${relativePath}"
            }
        }
        
        // æ£€æŸ¥çŸ¥è¯†åº“
        def kbDir = file("${aiWorkflowConfig.workspaceDir}/knowledge-base")
        println "ğŸ—„ï¸ çŸ¥è¯†åº“: ${kbDir.absolutePath}"
        println "   å­˜åœ¨: ${kbDir.exists() ? 'âœ…' : 'âŒ'}"
        
        println "=" * 50
        println "ç¯å¢ƒæ£€æŸ¥å®Œæˆï¼"
        
        // ç»™å‡ºä½¿ç”¨å»ºè®®
        println """
        
        ğŸ’¡ ä½¿ç”¨è¯´æ˜:
        1. gradle runAiWorkflow - æ‰§è¡Œå®Œæ•´å·¥ä½œæµï¼ˆéœ€è¦åœ¨Cursorä¸­æ‰§è¡ŒAIè§„åˆ™ï¼‰
        2. gradle generateFlinkSql - ä»…ç”ŸæˆSQL
        3. gradle validateFlinkSql - ä»…éªŒè¯SQL
        4. gradle updateErKnowledgeBase - ä»…æ›´æ–°çŸ¥è¯†åº“
        
        ğŸ¤– AIæ‰§è¡Œæ–¹å¼:
        - å½“å‰ç‰ˆæœ¬éœ€è¦åœ¨Cursor IDEä¸­æ‰‹åŠ¨æ‰§è¡ŒAIè§„åˆ™
        - æœªæ¥ç‰ˆæœ¬å°†æ”¯æŒè‡ªåŠ¨åŒ–AI APIè°ƒç”¨
        """
    }
}

// 6. åˆ›å»ºä¸šåŠ¡åŸŸè„šæ‰‹æ¶
task createFlinkDomain {
    group AI_TASK_GROUP
    description 'ä¸ºæ–°ä¸šåŠ¡åŸŸåˆ›å»ºæ ‡å‡†åŒ–çš„é¡¹ç›®ç»“æ„'
    
    doLast {
        def domainName = project.findProperty('domain') ?: 'new-domain'
        def domainDir = file("${aiWorkflowConfig.workspaceDir}/${domainName}")
        
        println "ğŸ—ï¸ åˆ›å»ºä¸šåŠ¡åŸŸè„šæ‰‹æ¶: ${domainName}"
        
        // åˆ›å»ºæ ‡å‡†ç›®å½•ç»“æ„
        [
            "${domainName}/sql",
            "${domainName}/deployment", 
            "${domainName}/validation",
            "${domainName}/docs",
            "${domainName}/workflow",
            "${domainName}/config",
            "${domainName}/.workflow"
        ].each { dir ->
            mkdir "${aiWorkflowConfig.workspaceDir}/${dir}"
        }
        
        // åˆ›å»ºrequestæ¨¡æ¿æ–‡ä»¶
        def requestFile = file("${aiWorkflowConfig.workspaceDir}/${domainName}/${domainName}-request-v3.md")
        if (!requestFile.exists()) {
            def templateContent = '''# ''' + domainName + ''' ä¸šåŠ¡åŸŸ Flink SQL éœ€æ±‚

## ğŸ¯ ä½œä¸šä¿¡æ¯

```yaml
job_info:
  name: "''' + domainName + '''å®æ—¶å®½è¡¨"
  domain: "''' + domainName + '''"
  event_type: "main_event"
  description: "''' + domainName + '''ä¸šåŠ¡åŸŸçš„å®æ—¶æ•°æ®å¤„ç†"
```

## ğŸ“Š å­—æ®µæ˜ å°„

```yaml
field_mapping:
  # ä»payloadæ˜ å°„çš„å­—æ®µ
  id: "CAST(payload.id AS BIGINT)"
  user_id: "payload.user_id"
  # æ·»åŠ æ›´å¤šå­—æ®µæ˜ å°„...
```

## ğŸ”— å…³è”å…³ç³»

```yaml
join_relationships:
  source_to_dim:
    source_table: "payload_entity"
    source_field: "foreign_key"
    target_table: "dimension_table"
    target_field: "primary_key"
    join_type: "LEFT JOIN"
```

## ğŸ—ºï¸ ERå›¾å®šä¹‰

### å®ä½“å…³ç³»å›¾ (Mermaidæ ¼å¼)
```mermaid
erDiagram
    source_table {
        string id PK "ä¸»é”®ID"
        string user_id "ç”¨æˆ·ID"
    }
    
    dimension_table {
        string id PK "ç»´è¡¨ä¸»é”®"
        string name "åç§°"
    }
    
    source_table }o--|| dimension_table : "å…³è”å…³ç³»"
```

## ğŸ“‹ ç‰¹æ®Šæ¡ä»¶

```yaml
special_conditions:
  filters:
    - "payload.is_delete = '0'"
    - "payload.status = 'ACTIVE'"
```
'''
            requestFile.text = templateContent
        }
        
        println """
        âœ… ä¸šåŠ¡åŸŸè„šæ‰‹æ¶åˆ›å»ºå®Œæˆï¼
        
        ğŸ“ åˆ›å»ºçš„ç›®å½•ç»“æ„:
        ${aiWorkflowConfig.workspaceDir}/${domainName}/
        â”œâ”€â”€ sql/                    # SQLæ–‡ä»¶
        â”œâ”€â”€ deployment/             # éƒ¨ç½²é…ç½®
        â”œâ”€â”€ validation/             # éªŒè¯æŠ¥å‘Š
        â”œâ”€â”€ docs/                   # æ–‡æ¡£
        â”œâ”€â”€ workflow/               # å·¥ä½œæµæŠ¥å‘Š
        â”œâ”€â”€ config/                 # é…ç½®æ–‡ä»¶
        â”œâ”€â”€ .workflow/              # å·¥ä½œæµçŠ¶æ€
        â””â”€â”€ ${domainName}-request-v3.md  # éœ€æ±‚æ–‡ä»¶æ¨¡æ¿
        
        ğŸ“ ä¸‹ä¸€æ­¥:
        1. ç¼–è¾‘ ${requestFile.absolutePath}
        2. å®Œå–„ä¸šåŠ¡éœ€æ±‚å’ŒERå›¾å®šä¹‰
        3. è¿è¡Œ gradle runAiWorkflow
        """
    }
}

// ä»»åŠ¡ä¾èµ–å…³ç³»
validateFlinkSql.dependsOn generateFlinkSql
updateErKnowledgeBase.dependsOn validateFlinkSql
runAiWorkflow.dependsOn checkAiEnvironment

publishing {
    publications {
        maven(MavenPublication) {
            from components.java
        }
    }
}